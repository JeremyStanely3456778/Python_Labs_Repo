{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2.1"
      ],
      "metadata": {
        "id": "V8VobGHDFgjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mOc8tF2BqFb",
        "outputId": "1fca782e-af44-432d-fc0f-613d27b6d30a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'string', '', '', '', 'was', 'meant', 'to', 'be', '', '', '', 'split', 'by', 'a', 'space']\n"
          ]
        }
      ],
      "source": [
        "#You need to split a string into fields, but the delimiters (and spacing around them) aren’t consistent throughout the string.\n",
        "import re\n",
        "string = 'This string   ,was meant to be   ,split by a space'\n",
        "split_str = re.split(r' |,', string)\n",
        "#returns a list structure once split function is called\n",
        "print(split_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2"
      ],
      "metadata": {
        "id": "-6PrPemdHxJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You need to check the start or end of a string for specific text patterns, such as filename extensions, URL schemes, and so on.\n",
        "\n",
        "def confirm_txtfile(filepath):\n",
        "  split_path = re.split(r'/', filepath)\n",
        "  if split_path[-1].endswith('.txt'):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "confirm_txtfile('this/is/my/file/path.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCXVWo9bHy7R",
        "outputId": "3461c8f2-c6f9-45aa-d53c-aeb78db4722c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3"
      ],
      "metadata": {
        "id": "rP8vvQxoLISp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You want to match text using the same wildcard patterns as are commonly used when working in Unix shells (e.g., .py, Dat[0-9].csv, etc.).\n",
        "from fnmatch import fnmatch, fnmatchcase\n",
        "def confirm_txtfile(filepath):\n",
        "  split_path = re.split(r'/', filepath)\n",
        "  if fnmatch(split_str[-1], '*.txt'):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "confirm_txtfile('this/is/my/file/path.txt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY2a0_fqKpIa",
        "outputId": "93e4daab-e4eb-4d5b-bed7-a51fcde4a517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4"
      ],
      "metadata": {
        "id": "DX818eybNUBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You want to match or search text for a specific pattern.\n",
        "\n",
        "social_media_post = 'This contains naughty nasty words. Doo, Poo, Sludge. This is what I think of that bands performance.'\n",
        "def check_obscene_lang(post):\n",
        "  post.lower()\n",
        "  if post == 'doo' or 'poo' or 'sludge':\n",
        "    return True\n",
        "  else:\n",
        "    False\n",
        "\n",
        "check_obscene_lang(social_media_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPGE_aRMNVxN",
        "outputId": "f84a22d0-00fd-43ac-c684-af51ce0f4922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5"
      ],
      "metadata": {
        "id": "xXVVWgSwQCIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You want to search for and replace a text pattern in a string.\n",
        "social_media_post = \"This contains nasty words. Doo, Poo, Sludge. This is what I think of that bands performance.\"\n",
        "clean_post=social_media_post.lower().replace(\"Doo\", \"a\").replace(\"Doo\", \"a\").replace(\"Sludge\", \"a\")\n",
        "print(clean_post)\n",
        "def clean_obscene_lang(post):\n",
        "  clean_post = post.lower()\n",
        "  clean_post = clean_post.replace(\"doo\", \" \").replace(\"poo\", \" \").replace(\"sludge\", \" \")\n",
        "  return clean_post\n",
        "print(clean_obscene_lang(social_media_post))\n",
        "\n",
        "# replace all instances of 'o' with 'a'\n",
        "new_string = string.replace(\"r\", \"e\" )\n",
        " \n",
        "print(string)\n",
        "print(new_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn1yONRdQDLg",
        "outputId": "7786e4da-61a4-4cf0-fee6-f8361d5686b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this contains nasty words. doo, poo, sludge. this is what i think of that bands performance.\n",
            "this contains nasty words.  ,  ,  . this is what i think of that bands performance.\n",
            "grrks FOR grrks\n",
            "geeks FOR geeks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.6"
      ],
      "metadata": {
        "id": "ixAd2isQb8R9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You need to search for and possibly replace text in a case-insensitive manner.\n",
        "upper_case_text = 'THIS IS ALL UPPER CASE.'\n",
        "if re.findall('upper', upper_case_text, flags=re.IGNORECASE):\n",
        "  print(re.sub('UPPER', 'lower', upper_case_text, flags=re.IGNORECASE))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WijbJPlob8ya",
        "outputId": "aaa677c9-55bd-4823-a977-42f84c01639d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THIS IS ALL lower CASE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.7"
      ],
      "metadata": {
        "id": "KWhLDhyxqyUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You’re trying to match a text pattern using regular expressions, but it is identifying the longest possible matches of a pattern. \n",
        "#Instead, you would like to change it to find the shortest possible match.\n",
        "\n",
        "#find things contained within quotation marks\n",
        "import re\n",
        "text = 'This text has multiple \" \" \" \" \" \" \" \".'\n",
        "string_pattern = re.compile(r'\\\"(.*?)\\\"')\n",
        "string_pattern.findall(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDx-MKB6qzsr",
        "outputId": "217eb8ee-03bc-4ba7-b7b4-102c31cf481e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ', ' ', ' ', ' ']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.8"
      ],
      "metadata": {
        "id": "-mTltslrv15g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You’re trying to match a block of text using a regular expression, but you need the match to span multiple lines.\n",
        "data = '''/* this is a\n",
        "               This is line one\n",
        "               This line 2.\n",
        "               This is line 3 */\n",
        "... '''\n",
        "pattern = re.compile(r'/\\*((?:.|\\n)*?)\\*/', re.DOTALL)\n",
        "pattern.findall(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1MIyC0Yv6e1",
        "outputId": "ce8ee91f-cf1b-42a0-d665-21a27b585274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' this is a\\n               This is line one\\n               This line 2.\\n               This is line 3 ']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.9"
      ],
      "metadata": {
        "id": "yRNEq2dtzwQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You’re working with Unicode strings, but need to make sure that all of the strings have the same underlying representation.\n",
        "import unicodedata as ud\n",
        "s1 = 'Spicy Jalape\\u00f1o'\n",
        "s2 = 'Spicy Jalapen\\u0303o'\n",
        "print(s1 == s2)\n",
        "def normalize_unicode(string):\n",
        "  normalized_str = ud.normalize('NFC', string)\n",
        "  return normalize_unicode\n",
        "\n",
        "normalized_s1 = normalize_unicode(s1)\n",
        "normalized_s2 = normalize_unicode(s2)\n",
        "print(normalized_s1 == normalized_s2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF7UGKjlyEvG",
        "outputId": "87e79d2d-0aad-483b-ec74-889060a8d0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.10"
      ],
      "metadata": {
        "id": "Y4P9U0av2BGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You are using regular expressions to process text, but are concerned about the handling of Unicode characters.\n",
        "\n",
        "pat = arabic = re.compile('[\\u0600-\\u06ff\\u0750-\\u077f\\u08a0-\\u08ff]+')\n",
        "s = 'straße'\n",
        "pat.match(s)              \n",
        "pat.match(s.upper())      \n",
        "s.upper()                \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xFWb_Uqu1ktM",
        "outputId": "568ab755-ee49-42a6-d200-e87c26099994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'STRASSE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.11"
      ],
      "metadata": {
        "id": "9BM7jjt-6J4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You want to strip unwanted characters, such as whitespace, from the beginning, end, or middle of a text string.\n",
        "str_data = '    --This string is dirty.  = -- '\n",
        "def clean_string(string):\n",
        "  string = string.strip()\n",
        "  string = string.replace('-', '').replace('=', '')\n",
        "  return string\n",
        "\n",
        "print(clean_string(str_data))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgf7vYLH6LN0",
        "outputId": "98a294d2-e967-4beb-de53-e5b3c05f47cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This string is dirty.   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.12"
      ],
      "metadata": {
        "id": "LVA-ywcBC_cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Some bored script kiddie has entered the text “pýtĥöñ” into a form on your web page and you’d like to clean it up somehow.\n",
        "import unicodedata\n",
        "import sys\n",
        "data = s = 'pýtĥöñ\\fis\\tawesome\\r\\n'\n",
        "\n",
        "def clean_unicode(data):\n",
        "  remap = {ord('\\t') : ' ', ord('\\f') : ' ', ord('\\r') : None, ord('\\n'): ' ', }\n",
        "  data_mapped = data.translate(remap)\n",
        "  cmb_chrs = dict.fromkeys(c for c in range(sys.maxunicode) if unicodedata.combining(chr(c)))\n",
        "  data_normalized2 = unicodedata.normalize('NFD', data_mapped)\n",
        "  data_translated = data_normalized2.translate(cmb_chrs)\n",
        "  return data_translated\n",
        "\n",
        "print(clean_unicode(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udT1OgSvLpsI",
        "outputId": "b0fee159-f4e2-4c37-862b-9b7d9beeda49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python is awesome \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.13"
      ],
      "metadata": {
        "id": "IGVm3Yb4g4x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You need to format text with some sort of alignment applied.\n",
        "text = 'This text will be centered.'\n",
        "text.ljust(10)\n",
        "text.rjust(10)\n",
        "text.center(1000, '*')\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H_YaIwhdlMP",
        "outputId": "32842248-161f-4070-aa71-db3700a3eefb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This text will be centered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.14"
      ],
      "metadata": {
        "id": "pPTLdT8_g61e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You want to combine many small strings together into a larger string.\n",
        "split_parts = ['Is', 'Chicago', 'Not', 'Chicago?']\n",
        "together = ' '.join(split_parts)\n",
        "print(together)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc1lhUN0g6Yi",
        "outputId": "85725adc-1023-483f-e11b-cfb781417eb5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Chicago Not Chicago?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.15"
      ],
      "metadata": {
        "id": "mke1e3dRoLEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You want to create a string in which embedded variable names are substituted with a string representation of a variable’s value.\n",
        "data = 'This {blank1} will be {blank2}.'\n",
        "print(data.format(blank1='string', blank2='embedded'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwI5Z-YaoOFR",
        "outputId": "f68529d8-3735-4a2f-83fd-8b2310e963b9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This string will be embedded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.16"
      ],
      "metadata": {
        "id": "3HNupmVrqDeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You have long strings that you want to reformat so that they fill a user-specified number of columns.\n",
        "import textwrap\n",
        "s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\\n",
        "the eyes, not around the eyes, don't look around the eyes, \\\n",
        "look into my eyes, you're under.\"\n",
        "print(textwrap.fill(s, 30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipWxRZaxqC42",
        "outputId": "a7ce144b-672c-497d-af3e-620e38abce4b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Look into my eyes, look into\n",
            "my eyes, the eyes, the eyes,\n",
            "the eyes, not around the eyes,\n",
            "don't look around the eyes,\n",
            "look into my eyes, you're\n",
            "under.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.17"
      ],
      "metadata": {
        "id": "lgvaq6H6rfbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ou want to replace HTML or XML entities such as &entity; or &#code; with their corresponding text. Alternatively, you need to produce text, but escape certain characters (e.g., <, >, or &).\n",
        "import html\n",
        "s = 'Elements are written as \"<tag>text</tag>\".'\n",
        "print(html.escape(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELDA4fyPreHg",
        "outputId": "34b0f77b-9b32-4f27-dffe-a3014e42372d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements are written as &quot;&lt;tag&gt;text&lt;/tag&gt;&quot;.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.18"
      ],
      "metadata": {
        "id": "GkclrrVV6kaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You have a string that you want to parse left to right into a stream of tokens.\n",
        "#!pip install nltk\n",
        "#nltk.download('punkt')\n",
        "import nltk \n",
        "sentence = 'This sentence will be tokenized.'\n",
        "tokenized_sentence = nltk. word_tokenize(sentence)\n",
        "print(tokenized_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWtQON7L6j07",
        "outputId": "c5a0c2e9-9b68-4712-9437-cea40891c6b0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'sentence', 'will', 'be', 'tokenized', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.19"
      ],
      "metadata": {
        "id": "FwNoXVIl_yI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You need to parse text according to a set of grammar rules and perform actions or build an abstract syntax tree representing the input. The grammar is small, so you’d prefer to just write the parser yourself as opposed to using some kind of framework.\n",
        "\n",
        "import re\n",
        "import collections\n",
        "\n",
        "# Token specification\n",
        "NUM    = r'(?P<NUM>\\d+)'\n",
        "PLUS   = r'(?P<PLUS>\\+)'\n",
        "MINUS  = r'(?P<MINUS>-)'\n",
        "TIMES  = r'(?P<TIMES>\\*)'\n",
        "DIVIDE = r'(?P<DIVIDE>/)'\n",
        "LPAREN = r'(?P<LPAREN>\\()'\n",
        "RPAREN = r'(?P<RPAREN>\\))'\n",
        "WS     = r'(?P<WS>\\s+)'\n",
        "\n",
        "master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES,\n",
        "DIVIDE, LPAREN, RPAREN, WS]))\n",
        "\n",
        "# Tokenizer\n",
        "Token = collections.namedtuple('Token', ['type','value'])\n",
        "\n",
        "def generate_tokens(text):\n",
        "  scanner = master_pat.scanner(text)\n",
        "  for m in iter(scanner.match, None):\n",
        "    tok = Token(m.lastgroup, m.group())\n",
        "    if tok.type != 'WS':\n",
        "      yield tok\n",
        "\n",
        "# Parser\n",
        "class ExpressionEvaluator:\n",
        "  '''\n",
        "  Implementation of a recursive descent parser.   Each method\n",
        "  implements a single grammar rule.  Use the ._accept() method\n",
        "  to test and accept the current lookahead token.  Use the ._expect()\n",
        "  method to exactly match and discard the next token on the input\n",
        "  (or raise a SyntaxError if it doesn't match).\n",
        "  '''\n",
        "\n",
        "  def parse(self,text):\n",
        "      self.tokens = generate_tokens(text)\n",
        "      self.tok = None             # Last symbol consumed\n",
        "      self.nexttok = None         # Next symbol tokenized\n",
        "      self._advance()             # Load first lookahead token\n",
        "      return self.expr()\n",
        "\n",
        "  def _advance(self):\n",
        "      'Advance one token ahead'\n",
        "      self.tok, self.nexttok = self.nexttok, next(self.tokens, None)\n",
        "\n",
        "  def _accept(self,toktype):\n",
        "      'Test and consume the next token if it matches toktype'\n",
        "      if self.nexttok and self.nexttok.type == toktype:\n",
        "          self._advance()\n",
        "          return True\n",
        "      else:\n",
        "          return False\n",
        "\n",
        "  def _expect(self,toktype):\n",
        "      'Consume next token if it matches toktype or raise SyntaxError'\n",
        "      if not self._accept(toktype):\n",
        "          raise SyntaxError('Expected ' + toktype)\n",
        "\n",
        "  # Grammar rules follow\n",
        "\n",
        "  def expr(self):\n",
        "      \"expression ::= term { ('+'|'-') term }*\"\n",
        "\n",
        "      exprval = self.term()\n",
        "      while self._accept('PLUS') or self._accept('MINUS'):\n",
        "          op = self.tok.type\n",
        "          right = self.term()\n",
        "          if op == 'PLUS':\n",
        "              exprval += right\n",
        "          elif op == 'MINUS':\n",
        "              exprval -= right\n",
        "      return exprval\n",
        "\n",
        "  def term(self):\n",
        "      \"term ::= factor { ('*'|'/') factor }*\"\n",
        "\n",
        "      termval = self.factor()\n",
        "      while self._accept('TIMES') or self._accept('DIVIDE'):\n",
        "          op = self.tok.type\n",
        "          right = self.factor()\n",
        "          if op == 'TIMES':\n",
        "              termval *= right\n",
        "          elif op == 'DIVIDE':\n",
        "              termval /= right\n",
        "      return termval\n",
        "\n",
        "  def factor(self):\n",
        "      \"factor ::= NUM | ( expr )\"\n",
        "\n",
        "      if self._accept('NUM'):\n",
        "          return int(self.tok.value)\n",
        "      elif self._accept('LPAREN'):\n",
        "          exprval = self.expr()\n",
        "          self._expect('RPAREN')\n",
        "          return exprval\n",
        "      else:\n",
        "          raise SyntaxError('Expected NUMBER or LPAREN')\n",
        "\n",
        "express_eval = ExpressionEvaluator()\n",
        "express_eval.parse('2 * 3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYIiGYPg-oNK",
        "outputId": "c62fc9b6-0be3-45dc-ada8-4701f1ab0949"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.20"
      ],
      "metadata": {
        "id": "goDLQntMGglw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You want to perform common text operations (e.g., stripping, searching, and replacement) on byte strings.\n",
        "data = b'String in byte format'\n",
        "target = b'i'\n",
        "a = data.decode('ascii')\n",
        "b = target.decode('ascii')\n",
        "#stripping\n",
        "print(data[6:-6]) # wanted to get the two center words used array slicing method\n",
        "\n",
        "count = 0\n",
        "#searching\n",
        "for char in a:\n",
        "  if char == b:\n",
        "    count += 1\n",
        "  \n",
        "print('found this many', count, 'within string')   \n",
        "    \n",
        "#replacing string char\n",
        "data.replace(b't', b'T')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD2JYuEOGii4",
        "outputId": "38eea9b2-93e1-490b-a2d0-e68fb45d8179"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b' in byte '\n",
            "found this many 2 within string\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'STring in byTe formaT'"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    }
  ]
}